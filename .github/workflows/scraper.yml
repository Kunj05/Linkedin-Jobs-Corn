name: LinkedIn Job Scraper

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install linkedin-jobs-scraper

      - name: Run scraper
        env:
          LI_AT_COOKIE: ${{ secrets.LI_AT_COOKIE }}
        run: python scraper.py

      - name: Prepare GitHub Pages
        run: |
          mkdir -p docs
          if [ -f docs/job_listings.json ]; then cp docs/job_listings.json docs/; else echo "job_listings.json missing"; exit 1; fi
          if [ -f docs/last_reset.json ]; then cp docs/last_reset.json docs/; else echo "last_reset.json missing"; fi
          if [ -f index.html ]; then cp index.html docs/; else echo "index.html missing"; exit 1; fi
          if [ -f docs/error.log ]; then cp docs/error.log docs/; else echo "No error.log"; fi
          touch docs/.nojekyll

      - name: Commit and push results
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add docs/job_listings.json docs/last_reset.json docs/index.html docs/error.log docs/.nojekyll
          git commit -m "Update job listings - $(date +'%Y-%m-%d %H:%M')" || echo "No changes to commit"
          git push
