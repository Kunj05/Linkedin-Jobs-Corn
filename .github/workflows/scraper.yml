name: LinkedIn Job Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install linkedin-jobs-scraper

      - name: Run scraper
        env:
          LI_AT_COOKIE: ${{ secrets.LI_AT_COOKIE }}
        run: |
          python scraper.py
          ls -R  # List all files to debug directory structure

      - name: Prepare GitHub Pages
        run: |
          echo "Directory contents before copy:"
          ls -la docs/ || echo "docs/ not found"
          if [ -f docs/job_listings.json ]; then echo "job_listings.json found"; else echo "job_listings.json missing"; exit 1; fi
          if [ -f docs/last_reset.json ]; then echo "last_reset.json found"; else echo "last_reset.json missing"; fi
          if [ -f index.html ]; then cp index.html docs/; echo "Copied index.html"; else echo "index.html missing"; exit 1; fi
          if [ -f docs/error.log ]; then echo "error.log found"; else echo "No error.log"; fi

      - name: Commit and push results
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add docs/job_listings.json docs/last_reset.json docs/index.html docs/error.log docs/.nojekyll
          git commit -m "Update job listings - $(date +'%Y-%m-%d %H:%M')" || echo "No changes to commit"
          git push
